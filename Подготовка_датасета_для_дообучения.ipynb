{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO48wqe+rEb6sKONjjfz0cX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "945d7df864ba48008d9586516f4a83b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df3878d752eb431a857f4be413f31fa1",
              "IPY_MODEL_791f5c5d080a4ab68625c5c1f632e5d8",
              "IPY_MODEL_cfbc9866407444b69777bbd16893a3f8"
            ],
            "layout": "IPY_MODEL_2a77bd9fedcf46b491a80330209bf701"
          }
        },
        "df3878d752eb431a857f4be413f31fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f473e6816704458e96cb4985bc9af810",
            "placeholder": "​",
            "style": "IPY_MODEL_c2120e547ed04b1bb1dacda6f77b94e3",
            "value": "100%"
          }
        },
        "791f5c5d080a4ab68625c5c1f632e5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab445ccac2f1409f8534b8b6a98fe9b0",
            "max": 6534387,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38d71d2aa0e04cf4a30b9c58e47f3793",
            "value": 6534387
          }
        },
        "cfbc9866407444b69777bbd16893a3f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52c29dccbf054f72a2805810d7d82f18",
            "placeholder": "​",
            "style": "IPY_MODEL_0ac66c9120b74a439958d2b139253ec9",
            "value": " 6.23M/6.23M [00:00&lt;00:00, 86.3MB/s]"
          }
        },
        "2a77bd9fedcf46b491a80330209bf701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f473e6816704458e96cb4985bc9af810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2120e547ed04b1bb1dacda6f77b94e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab445ccac2f1409f8534b8b6a98fe9b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d71d2aa0e04cf4a30b9c58e47f3793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52c29dccbf054f72a2805810d7d82f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac66c9120b74a439958d2b139253ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75127efecc9046f8ad6302325ebfe31e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6873ba591fa540de9eafb3b87f19750a",
              "IPY_MODEL_b69c0c5c80c8488ab05399aaa573fa83",
              "IPY_MODEL_54009b9b92a8438bbedf90f1d0c87967"
            ],
            "layout": "IPY_MODEL_84d4747f8965495295ad72a04483a907"
          }
        },
        "6873ba591fa540de9eafb3b87f19750a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_517636d0f39a42459c3e427f25e6f3a4",
            "placeholder": "​",
            "style": "IPY_MODEL_d339860f8b6e49b3a23c9979ab549325",
            "value": "100%"
          }
        },
        "b69c0c5c80c8488ab05399aaa573fa83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_926deb892be045fb8cd0f93e65320448",
            "max": 773236,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b793feca5f4408aa79aab3437c011e7",
            "value": 773236
          }
        },
        "54009b9b92a8438bbedf90f1d0c87967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c26a215433df48edae92bd8f679107ee",
            "placeholder": "​",
            "style": "IPY_MODEL_85e80bac981a4ba3acee246c3a2fdbc2",
            "value": " 755k/755k [00:00&lt;00:00, 14.1MB/s]"
          }
        },
        "84d4747f8965495295ad72a04483a907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517636d0f39a42459c3e427f25e6f3a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d339860f8b6e49b3a23c9979ab549325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "926deb892be045fb8cd0f93e65320448": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b793feca5f4408aa79aab3437c011e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c26a215433df48edae92bd8f679107ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e80bac981a4ba3acee246c3a2fdbc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vokulovskiy/Counting-people-at-the-gate/blob/main/%D0%9F%D0%BE%D0%B4%D0%B3%D0%BE%D1%82%D0%BE%D0%B2%D0%BA%D0%B0_%D0%B4%D0%B0%D1%82%D0%B0%D1%81%D0%B5%D1%82%D0%B0_%D0%B4%D0%BB%D1%8F_%D0%B4%D0%BE%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчет количества рабочих на стройке\n",
        "#Задача: дообучить нейросеть данными с видеокамеры\n",
        "#создаем датасет с помощью предобученной модели\n",
        "%pip install ultralytics\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "# Для работы с файлами\n",
        "import os \n",
        "import shutil\n",
        "model = YOLO('yolov8m.pt')\n",
        "path='/content/runs/detect/predict/'\n",
        "txt_path='/content/txt/'\n",
        "img_path='/content/img/'\n",
        "os.mkdir(txt_path)                 #при помощии команды \"mkdir\" создадим новую папку\n",
        "os.mkdir(img_path)                 #при помощии команды \"mkdir\" создадим новую папку\n",
        "## Подключение гугл диска для сохранения модели\n",
        "## с гугл диска быстро работает, и не нужно каждый раз копировать файл на колаб машину\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ],
      "metadata": {
        "id": "AtXhRarCZsvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b26ay9EAEly"
      },
      "outputs": [],
      "source": [
        "#os.remove(path+'labels/image0.txt') \n",
        "# Загрузка видеофайла\n",
        "cap = cv2.VideoCapture('/content/gdrive/MyDrive/models/camera3_01.mp4')\n",
        "kadr=0\n",
        "kadrold=-5\n",
        "while 30:\n",
        "    # Чтение кадра из видео\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    kadr+=1\n",
        "    if kadr-kadrold>5:\n",
        "        print('Кадр:',kadr)\n",
        "        if os.path.isfile(path+'labels/image0.txt'):\n",
        "            os.remove(path + 'labels/image0.txt')\n",
        "        pred=model.predict(source=frame, save=False, save_txt=True, classes=0)  # save predictions as labels ,name='predict'\n",
        "        if len(pred[0])>2: # берем кадры где больше 2 человек и подряд берем только 1 из 5 кадров\n",
        "            kadrold=kadr\n",
        "            # Сохранение кадра как изображения\n",
        "            cv2.imwrite(img_path+'image'+str(1000+kadr)+'.jpg', frame)\n",
        "            # Сохранение рамок\n",
        "            if os.path.exists(path+'labels/image0.txt'):\n",
        "                os.rename(path+'labels/image0.txt', txt_path+'image'+str(1000+kadr)+'.txt') \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Сжимаем файлы\n",
        "import pathlib\n",
        "import zipfile\n",
        "\n",
        "directory = pathlib.Path(img_path)\n",
        "\n",
        "with zipfile.ZipFile(\"/content/img.zip\", mode=\"w\") as archive:\n",
        "   for file_path in directory.iterdir():\n",
        "       archive.write(file_path, arcname=file_path.name)\n",
        "\n",
        "directory = pathlib.Path(txt_path)\n",
        "\n",
        "with zipfile.ZipFile(\"/content/txt.zip\", mode=\"w\") as archive:\n",
        "   for file_path in directory.iterdir():\n",
        "       archive.write(file_path, arcname=file_path.name)\n",
        "\n"
      ],
      "metadata": {
        "id": "FO1d9Ug7AYpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Копируем на свой гугл диск\n",
        "shutil.copyfile(\"/content/img.zip\", \"/content/gdrive/MyDrive/models/img.zip\")\n",
        "shutil.copyfile(\"/content/txt.zip\", \"/content/gdrive/MyDrive/models/txt.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "29JYEkOkb-OT",
        "outputId": "0903650b-c66d-4448-b593-c206222cccfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/models/txt.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дальше отключаемся от колаба и работаем на своем компьютере локально.\n",
        "\n",
        "Копируем из колаба файлы на локальный комп.\n",
        "\n",
        "В моем примере я скопировал изображения в каталог c:\\temp\\img\\, метки в каталог c:\\temp\\txt\\\n",
        "\n",
        "Для поготовки датасета я выбрал программу 'VGG image annotator' https://www.robots.ox.ac.uk/~vgg/software/via/.  \n",
        "\n",
        "Скачать можно здесь https://www.robots.ox.ac.uk/~vgg/software/via/downloads/via-2.0.12.zip (~400KB)\n",
        "\n",
        "# **Обзор**\n",
        "VGG Image Annotator — это простое и автономное программное обеспечение для ручной аннотации изображений, аудио и видео. VIA работает в веб-браузере и не требует установки или настройки. Полное программное обеспечение VIA умещается на одной автономной HTML-странице размером менее 400 килобайт, которая запускается как автономное приложение в большинстве современных веб-браузеров.\n",
        "\n",
        "VIA — это проект с открытым исходным кодом , основанный исключительно на HTML, Javascript и CSS (без зависимости от внешних библиотек). VIA разработан в Visual Geometry Group (VGG) и выпущен под лицензией BSD-2 , что позволяет использовать его как для академических проектов, так и для коммерческих приложений.\n",
        "\n",
        "\n",
        "\n",
        "В этой программе свой формат хранения меток, поэтому нужен декодер.\n",
        "\n",
        "\n",
        "Код, который ниже нужно выполнить на локальном питоне не на колабе.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXCkwj2pudD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOLO to CSV for VGG image annotator\n",
        "import os\n",
        "import cv2\n",
        "txt_dir = \"C:/Temp/txt/\"\n",
        "img_dir = \"C:/Temp/img/\"\n",
        "spf = os.listdir(txt_dir)\n",
        "spi = os.listdir(img_dir)\n",
        "src = cv2.imread(img_dir+spi[0], cv2.IMREAD_UNCHANGED)\n",
        "width = src.shape[1]\n",
        "height = src.shape[0]\n",
        "my_file = open(img_dir + \"labels.csv\", \"w+\")\n",
        "my_file.write('filename,file_size,file_attributes,region_count,region_id,region_shape_attributes,region_attributes\\n')\n",
        "for patch in spf:\n",
        "    if patch.split('.')[1] == 'txt':\n",
        "        stats = os.stat(img_dir + patch.split('.')[0] + '.jpg')\n",
        "        size = stats.st_size\n",
        "        with open(txt_dir + patch) as file:\n",
        "            sss = file.readlines()\n",
        "            sss = [x for x in sss if x]\n",
        "            for i, s in enumerate(sss):\n",
        "                cls = s.split()[0]\n",
        "                coord = [float(i) for i in s.split()[1:]]\n",
        "                #YOLO, метки находятся в текстовых файлах с нормализованными xmax, ymax, width, height\n",
        "                #VIA: xcenter, ycenter, width, height\n",
        "                x = coord[0] * width\n",
        "                y = coord[1] * height\n",
        "                w = coord[2] * width\n",
        "                h = coord[3] * height\n",
        "                coord[0] = x - w / 2\n",
        "                coord[1] = y - h / 2\n",
        "                coord[2] = w\n",
        "                coord[3] = h\n",
        "                coord = [str(int(i)) for i in coord]\n",
        "                st = patch.split('.')[0] + '.jpg,' + str(size) + ',\"{}\",' + str(len(sss)) + ',' + str(i) + \\\n",
        "                     ',\"{\"\"name\"\":\"\"rect\"\",\"\"x\"\":' + coord[0] + ',\"\"y\"\":' + coord[1] + ',\"\"width\"\":' + coord[2] + \\\n",
        "                     ',\"\"height\"\":' + coord[3] + '}\",\"{\"\"'+cls+'\"\":\"\"'+cls+'\"\"}\"'\n",
        "                my_file.write(st + '\\n')\n",
        "                print(st)\n",
        "my_file.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Kjc7rjpvcxBq",
        "outputId": "d18e11d1-dd31-4823-fdf2-f9edec02fa5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/models/txt.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В результате выполнения программы должен получиться файл C:\\Temp\\img\\labels.csv\n",
        "   \n",
        "\n",
        "*   Качаем VGG Image Annotator, распаковываем его в каталог на локальной машине(у меня C:\\Temp\\via-2.0.12\\). Запускаем via.html\n",
        "*   Project -> Add local files -> выбираем все наши изображения и нажимаем \"открыть\"\n",
        "*   Annotation -> Import Annotations (from csv) -> выбираем наш файл C:\\Temp\\img\\labels.csv\n",
        "\n",
        "\n",
        "Сейчас мы видим все предсказанные рамки на наших изображениях.\n",
        "\n",
        "*   Пробегаем по кадрам, удаляем лишние, добавляем не достающие, изменяем не правильные.\n",
        "\n",
        "![Снимок.PNG](data:image/png;base64,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)\n",
        "\n",
        "Атрибуты нужно настроить как на картинке, иначе потом проблемы будут. Проверить можно Annotation -> Preview Annotations\n",
        "*   Сохраняем обязательно проект\n",
        "*   Annotation -> Export Annotations (as csv). копируем полученный файл в C:\\Temp\\img\\via_project.csv\n",
        "*   Делаем обратное действие: кодируем датасет в формат YOLO. Так же выполняем на локальной машине\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3beha2hQzDYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV from 'VGG image annotator' to YOLO\n",
        "import os, cv2, shutil\n",
        "from random import shuffle\n",
        "\n",
        "shake = True  # Нужно ли перемешивать выборки\n",
        "proc_valid = 20  # процент проверочной выборки\n",
        "zip_file = \"C:/Temp/dataset.zip\"\n",
        "proj_dir = \"C:/Temp/yolo/\"\n",
        "img_dir = \"C:/Temp/img/\"\n",
        "spi = os.listdir(img_dir)\n",
        "sp = []\n",
        "for s in spi:  # оставляем только имя файла без расширения\n",
        "    if s.split('.')[1] == 'jpg':\n",
        "        sp.append(s.split('.')[0])\n",
        "if not os.path.exists(proj_dir): os.mkdir(proj_dir)\n",
        "if not os.path.exists(proj_dir + 'txt/'): os.mkdir(proj_dir + 'txt/')\n",
        "src = cv2.imread(img_dir + sp[0] + '.jpg', cv2.IMREAD_UNCHANGED)  # считываем параметры картинки\n",
        "width = src.shape[1]\n",
        "height = src.shape[0]\n",
        "label_f = ''\n",
        "with open(img_dir + \"via_project.csv\", \"r\") as f:\n",
        "    line = f.readline()  # Первая строка не нужна\n",
        "    l = open(img_dir + sp[0] + '.jpg', \"r\")  # открываем любой файл\n",
        "    while True:\n",
        "        # считываем строку\n",
        "        line = f.readline()\n",
        "        # прерываем цикл, если строка пустая\n",
        "        if not line:\n",
        "            break\n",
        "        line = line.split(',')\n",
        "        name_f = line[0].split('.')[0]  # имя файла без расширения\n",
        "        if len(line) == 11 and name_f in sp:  # отсекаем не правильные рамки и удаленные файлы\n",
        "            if len(line[10].split('\"')) < 4:  # Если вдруг класс не поставлен, ставим 0\n",
        "                cls = '0'\n",
        "            else:\n",
        "                cls = line[10].split('\"')[3]\n",
        "            if label_f != name_f:\n",
        "                if not l.closed: l.close()\n",
        "                label_f = name_f\n",
        "                l = open(proj_dir + 'txt/' + name_f + '.txt', \"w+\")\n",
        "            # VIA: xcenter, ycenter, width, height\n",
        "            # YOLO, метки находятся в текстовых файлах с нормализованными xmax, ymax, width, height\n",
        "            x = int(line[6].split(':')[1])\n",
        "            y = int(line[7].split(':')[1])\n",
        "            w = int(line[8].split(':')[1])\n",
        "            h = int(line[9].split(':')[1].split('}')[0])\n",
        "            x = str((x + w / 2) / width)\n",
        "            y = str((y + h / 2) / height)\n",
        "            w = str(w / width)\n",
        "            h = str(h / height)\n",
        "            st = cls + ' ' + x + ' ' + y + ' ' + w + ' ' + h\n",
        "            l.write(st + '\\n')\n",
        "            print(label_f, st)\n",
        "    if not l.closed: l.close()\n",
        "\n",
        "# Перемешиваем и делим на тренировочную и проверочную выборки\n",
        "if shake: shuffle(sp)\n",
        "# Готовим структуру каталогов\n",
        "shutil.rmtree(proj_dir + 'train/', ignore_errors=True)\n",
        "shutil.rmtree(proj_dir + 'valid/', ignore_errors=True)\n",
        "if not os.path.exists(proj_dir + 'train/'): os.mkdir(proj_dir + 'train/')\n",
        "if not os.path.exists(proj_dir + 'valid/'): os.mkdir(proj_dir + 'valid/')\n",
        "if not os.path.exists(proj_dir + 'train/images/'): os.mkdir(proj_dir + 'train/images/')\n",
        "if not os.path.exists(proj_dir + 'train/labels/'): os.mkdir(proj_dir + 'train/labels/')\n",
        "if not os.path.exists(proj_dir + 'valid/images/'): os.mkdir(proj_dir + 'valid/images/')\n",
        "if not os.path.exists(proj_dir + 'valid/labels/'): os.mkdir(proj_dir + 'valid/labels/')\n",
        "# Перемещаем файлы по каталогам\n",
        "for n in sp[:len(sp) * proc_valid // 100]:  # проверочная выборка\n",
        "    shutil.move(proj_dir + 'txt/' + n + '.txt', proj_dir + 'valid/labels/')\n",
        "    shutil.copy(img_dir + n + '.jpg', proj_dir + 'valid/images/')\n",
        "for n in sp[len(sp) * proc_valid // 100:]:  # тестовая выборка\n",
        "    shutil.move(proj_dir + 'txt/' + n + '.txt', proj_dir + 'train/labels/')\n",
        "    shutil.copy(img_dir + n + '.jpg', proj_dir + 'train/images/')\n",
        "shutil.rmtree(proj_dir + 'txt/', ignore_errors=True)\n",
        "print('Тренировочная выборка:', len(sp[len(sp) * proc_valid // 100:]), '  Проверочная выборка:',\n",
        "      len(sp[:len(sp) * proc_valid // 100]))\n",
        "\n",
        "# создаем файл .yaml\n",
        "s = \"\"\"\n",
        "\n",
        "        train: ../train/images\n",
        "        val: ../valid/images\n",
        "        test: \n",
        "\n",
        "        # number of classes\n",
        "        nc: 1\n",
        "\n",
        "        # class names\n",
        "        names: ['person']\n",
        "\"\"\"\n",
        "with open(proj_dir + \"data.yaml\", \"w+\") as f:\n",
        "    f.write(s)\n",
        "\n",
        "# Сжимаем файлы\n",
        "import pathlib\n",
        "from zipfile import ZipFile\n",
        "\n",
        "directory = pathlib.Path(proj_dir)\n",
        "\n",
        "with ZipFile(zip_file, \"w\") as archive:\n",
        "    for file_path in directory.rglob(\"*\"):\n",
        "        archive.write(file_path, arcname=file_path.relative_to(directory))\n",
        "\n",
        "shutil.rmtree(proj_dir, ignore_errors=True) # Стираем лишние файлы, но только если zip файл поместили не туда же\n",
        "\n",
        "stats = os.stat(zip_file)\n",
        "print(f'Размер архива с датасетом: {stats.st_size} bytes ({zip_file})')\n"
      ],
      "metadata": {
        "id": "yMQi8ymnjtfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получился ахив dataset.zip, копируем его на свой гугл диск (я копирую в каталог models).\n",
        "\n",
        "Далее работаем в колабе."
      ],
      "metadata": {
        "id": "kzvW36c3j_7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "## Подключение гугл диска \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_DSCeR_z4QG",
        "outputId": "1415fd32-f47f-45a6-cccc-1000522e0a74"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GhLtlHEQ21ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "TRAIN_DIR = '/content/my_yolo/'   #полный путь к папке сохраним в переменной TRAIN_DIR\n",
        "os.mkdir(TRAIN_DIR)                 #при помощии команды \"mkdir\" создадим новую папку\n",
        "!unzip -q -o /content/gdrive/MyDrive/models/dataset.zip  -d {TRAIN_DIR} "
      ],
      "metadata": {
        "id": "gRUXhMcf1g-f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ключ -q минимизирует информационные сообщения распаковщика\n",
        "\n",
        "ключ -o включает режим перезаписи, на случай, если по путям распаковки существуют другие файлы\n",
        "\n",
        "ключ -d после пробела указывается каталог, в который нужно распаковать архив\n",
        "\n",
        "вы можете самостоятельно поэкспериментировать с ключами unzip. Чтобы посмотреть справку по другим опциям программы можно запустить ее с ключом --h\n",
        "\n",
        "\n",
        "#Обучение модели\n",
        "\n",
        "Вот пояснения ко всем аргументам , которые мы используем:\n",
        "\n",
        "task: Хотим ли мы detect, segment или classify на выбранном нами наборе данных.\n",
        "\n",
        "mode: Режим может быть либо train, val или predict. Поскольку мы проводим обучение, оно должно быть train.\n",
        "\n",
        "model: Модель, которую мы хотим использовать. Здесь мы используем модель YOLOv8 Nano, предварительно обученную на наборе данных COCO.\n",
        "\n",
        "imgsz: Размер изображения. Разрешение по умолчанию - 640.\n",
        "\n",
        "data: Путь к файлу YAML dataset.\n",
        "\n",
        "epochs: Количество эпох, для которых мы хотим обучаться.\n",
        "\n",
        "batch: Размер пакета для загрузчика данных. Вы можете увеличить или уменьшить его в зависимости от доступности памяти вашего графического процессора.\n",
        "\n",
        "name: Имя каталога результатов для runs/detect."
      ],
      "metadata": {
        "id": "k1P-sNzw209X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Обучение модели\n",
        "from ultralytics import YOLO\n",
        " \n",
        "# Load the model.\n",
        "model = YOLO('yolov8n.pt')\n",
        " \n",
        "# Training.\n",
        "results = model.train(\n",
        "   data='/content/my_yolo/data.yaml',\n",
        "   imgsz=640,\n",
        "   epochs=10,\n",
        "   batch=8,\n",
        "   name='yolov8n_custom')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "945d7df864ba48008d9586516f4a83b1",
            "df3878d752eb431a857f4be413f31fa1",
            "791f5c5d080a4ab68625c5c1f632e5d8",
            "cfbc9866407444b69777bbd16893a3f8",
            "2a77bd9fedcf46b491a80330209bf701",
            "f473e6816704458e96cb4985bc9af810",
            "c2120e547ed04b1bb1dacda6f77b94e3",
            "ab445ccac2f1409f8534b8b6a98fe9b0",
            "38d71d2aa0e04cf4a30b9c58e47f3793",
            "52c29dccbf054f72a2805810d7d82f18",
            "0ac66c9120b74a439958d2b139253ec9",
            "75127efecc9046f8ad6302325ebfe31e",
            "6873ba591fa540de9eafb3b87f19750a",
            "b69c0c5c80c8488ab05399aaa573fa83",
            "54009b9b92a8438bbedf90f1d0c87967",
            "84d4747f8965495295ad72a04483a907",
            "517636d0f39a42459c3e427f25e6f3a4",
            "d339860f8b6e49b3a23c9979ab549325",
            "926deb892be045fb8cd0f93e65320448",
            "9b793feca5f4408aa79aab3437c011e7",
            "c26a215433df48edae92bd8f679107ee",
            "85e80bac981a4ba3acee246c3a2fdbc2"
          ]
        },
        "id": "WosPJ01yy_2A",
        "outputId": "9e402e82-b144-4c49-d387-c564ddd0391e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/6.23M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "945d7df864ba48008d9586516f4a83b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.58 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/my_yolo/data.yaml, epochs=10, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8n_custom, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/yolov8n_custom\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/755k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75127efecc9046f8ad6302325ebfe31e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.Detect                [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8n_custom', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/my_yolo/train/labels... 239 images, 0 backgrounds, 0 corrupt: 100%|██████████| 239/239 [00:00<00:00, 1977.02it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/my_yolo/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/my_yolo/valid/labels... 59 images, 0 backgrounds, 0 corrupt: 100%|██████████| 59/59 [00:00<00:00, 2132.96it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/my_yolo/valid/labels.cache\n",
            "Plotting labels to runs/detect/yolov8n_custom/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/yolov8n_custom\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/10      1.15G     0.8678      2.753      1.072         25        640: 100%|██████████| 30/30 [00:12<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]\n",
            "                   all         59        217     0.0121      0.986      0.611      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/10      1.35G     0.8041      1.634     0.9787         22        640: 100%|██████████| 30/30 [00:09<00:00,  3.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.47it/s]\n",
            "                   all         59        217      0.882      0.627      0.784      0.551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/10      1.35G     0.8007      1.301     0.9937         23        640: 100%|██████████| 30/30 [00:10<00:00,  2.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.40it/s]\n",
            "                   all         59        217      0.924      0.615      0.812      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/10      1.35G     0.8257      1.252      1.023         22        640: 100%|██████████| 30/30 [00:10<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.46it/s]\n",
            "                   all         59        217      0.884      0.702      0.844       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/10      1.35G     0.8801      1.238      1.036         25        640: 100%|██████████| 30/30 [00:10<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.40it/s]\n",
            "                   all         59        217      0.798      0.742      0.851       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/10      1.35G     0.7943      1.162     0.9835         21        640: 100%|██████████| 30/30 [00:10<00:00,  2.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.40it/s]\n",
            "                   all         59        217      0.935      0.732      0.867       0.66\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/10      1.35G     0.7779      1.083     0.9821         23        640: 100%|██████████| 30/30 [00:10<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.74it/s]\n",
            "                   all         59        217      0.923       0.76      0.888      0.706\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/10      1.35G     0.7716      1.066     0.9743         22        640: 100%|██████████| 30/30 [00:13<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.37it/s]\n",
            "                   all         59        217      0.881      0.742      0.887      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/10      1.35G     0.7185      1.019     0.9663         25        640: 100%|██████████| 30/30 [00:11<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.06it/s]\n",
            "                   all         59        217       0.86      0.794      0.902      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/10      1.35G     0.6648     0.9593      0.935         22        640: 100%|██████████| 30/30 [00:10<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]\n",
            "                   all         59        217      0.876      0.814       0.91      0.744\n",
            "\n",
            "10 epochs completed in 0.040 hours.\n",
            "Optimizer stripped from runs/detect/yolov8n_custom/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/yolov8n_custom/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/yolov8n_custom/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.58 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.21s/it]\n",
            "                   all         59        217      0.876      0.813       0.91      0.742\n",
            "Speed: 4.3ms preprocess, 9.1ms inference, 0.0ms loss, 7.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/yolov8n_custom\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EuL8Sii34kqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Оценка обучения\n",
        "model.val()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgCNbTrf4lFt",
        "outputId": "5799765e-f4ff-4220-efff-27df4373e41d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.58 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/my_yolo/valid/labels.cache... 59 images, 0 backgrounds, 0 corrupt: 100%|██████████| 59/59 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.13it/s]\n",
            "                   all         59        217      0.876      0.814       0.91      0.743\n",
            "Speed: 3.6ms preprocess, 13.2ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/yolov8n_custom2\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.yolo.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x7f63eefcef70>\n",
              "fitness: 0.7599545081219266\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.74327])\n",
              "names: {0: 'person'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.8760690041231302, 'metrics/recall(B)': 0.8144062129783098, 'metrics/mAP50(B)': 0.9101122363792373, 'metrics/mAP50-95(B)': 0.7432703160933364, 'fitness': 0.7599545081219266}\n",
              "save_dir: PosixPath('runs/detect/yolov8n_custom2')\n",
              "speed: {'preprocess': 3.5849991491285422, 'inference': 13.248447644508492, 'loss': 0.0025134975627317266, 'postprocess': 6.329152543665999}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Сохраняем лучшую модель на гугл диск, дальше используем ее для детекции\n",
        "import shutil\n",
        "shutil.copyfile(\"runs/detect/yolov8n_custom/weights/best.pt\", \"/content/gdrive/MyDrive/models/yolov8n_mod.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcJ2HxSU5FvF",
        "outputId": "379188f6-3f7e-4775-8b17-4c9f8d6a8cb3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    }
  ]
}